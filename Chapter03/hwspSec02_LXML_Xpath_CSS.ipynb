{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hwspSec2_LXML_Xpath_CSS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3To0R4V-or1"
      },
      "source": [
        "## LXML "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fmp1wP726p_"
      },
      "source": [
        "### Example 1: Reading XML file and traversing through elements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJFkE1KAVzfS"
      },
      "source": [
        "from lxml import etree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wQk_0Jb3XJu"
      },
      "source": [
        "!npx degit PacktPublishing/Hands-On-Web-Scraping-with-Python/Chapter03 -f chp3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD_DVoXYUSq3"
      },
      "source": [
        "import os\n",
        "os.chdir('chp3')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pk51Unnq4hAH"
      },
      "source": [
        "xml = open(\"food.xml\",\"rb\").read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVhADP0r5G0G"
      },
      "source": [
        "tree = etree.XML(xml) \n",
        "#tree = etree.fromstring(xml)\n",
        "#tree = etree.parse(xml)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiTAth1W5KOw"
      },
      "source": [
        "print(tree)\n",
        "print(type(tree))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8kSOc-l5lnK"
      },
      "source": [
        "for element in tree.iter():\n",
        "  print(\"%s - %s\"%(element.tag,element.text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2vEulug530e"
      },
      "source": [
        "for element in tree.iter('price','name'):\n",
        "  print(\"%s - %s\"%(element.tag,element.text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-FJLDHS6AcC"
      },
      "source": [
        "#to overcome encoding error use decoding or else parse() is effective approach\n",
        "tree = etree.parse(\"food.xml\")\n",
        "#iterate through 'name' and print text content\n",
        "for element in tree.iter('name'):\n",
        " print(element.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORhgAVHJ6pFT"
      },
      "source": [
        "for element in tree.iter('name','rating','feedback'):\n",
        " print(\"{} - {}\".format(element.tag, element.text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHwmvkuw6y0q"
      },
      "source": [
        "### Example 2: Reading HTML doc using lxml.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15IWsLny6sTp"
      },
      "source": [
        "from lxml import html\n",
        "from urllib.request import urlopen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8s4Lgpj7F_W"
      },
      "source": [
        "root = html.parse(urlopen('http://httpbin.org/forms/post')).getroot()\n",
        "tree = html.parse(urlopen('http://httpbin.org/forms/post'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X26VDa357JwS"
      },
      "source": [
        "print(type(root))\n",
        "print(type(tree))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCzDeLvq7Q6A"
      },
      "source": [
        "p = root.find('.//p') #find first <p> from root\n",
        "print(p.text_content()) # Customer name:\n",
        "print(root.findtext('.//p/label')) #Customer name:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES6f3klo7kvD"
      },
      "source": [
        "elemP = root.findall('.//p') #find all <p> element from root\n",
        "for p in elemP :\n",
        " print(p.text_content())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCDBTyrQ7lft"
      },
      "source": [
        "print(root.xpath('//p/label/input/@value'))\n",
        "print(root.xpath('//legend/text()'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFJGL7p-8uHe"
      },
      "source": [
        "pip install cssselect"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7RzCIN683uh"
      },
      "source": [
        "for e in root.cssselect('p>label'):\n",
        " print(e.text_content())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p431m4LI7sKg"
      },
      "source": [
        "for e in root.cssselect('form > p'):\n",
        " print(e.text_content())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O242hUnm74fN"
      },
      "source": [
        "print(root.forms[0].action) #http://httpbin.org/post\n",
        "print(root.forms[0].keys()) #['method', 'action']\n",
        "print(root.forms[0].items()) #[('method', 'post'), ('action', '/post')]\n",
        "print(root.forms[0].method) # POST"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VABEvdah9bGM"
      },
      "source": [
        "### Example 3: Reading & parsing HTML for retrieving HTML form type element attributes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_MpF9h18_VC"
      },
      "source": [
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3m6agYV9uO-"
      },
      "source": [
        "response = requests.get('http://httpbin.org/forms/post')\n",
        "# build the DOM Tree\n",
        "tree = html.fromstring(response.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTZJW7sw9zXU"
      },
      "source": [
        "for element in tree.iter('input'):\n",
        " print(\"Element: %s \\n\\tvalues(): %s \\n\\tattrib: %s \\n\\titems(): %s \\n\\tkeys(): %s\"%\n",
        " (element.tag, element.values(),element.attrib,element.items(),element.keys()))\n",
        " print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoIhSwps-tE7"
      },
      "source": [
        "## Web Scraping using LXML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yin-nLsx-3Cf"
      },
      "source": [
        "### Example 1: Extract selected data using lxml.html.parse from single page"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRen6Y7a-zv4"
      },
      "source": [
        "import lxml.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKUxnD6M_I3I"
      },
      "source": [
        "musicUrl= \"http://books.toscrape.com/catalogue/category/books/music_14/index.html\"\n",
        "doc = lxml.html.parse(musicUrl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocTCVat6_LYJ"
      },
      "source": [
        "#This path has been found using Devtools manually\n",
        "#base element\n",
        "articles = doc.xpath(\"//*[@id='default']/div/div/div/div/section/div[2]/ol/li[1]/article\")[0]\n",
        "#individual element inside base\n",
        "title = articles.xpath(\"//h3/a/text()\")\n",
        "price = articles.xpath(\"//div[2]/p[contains(@class,'price_color')]/text()\")\n",
        "availability = articles.xpath(\"//div[2]/p[2][contains(@class,'availability')]/text()[normalize-space()]\")\n",
        "imageUrl = articles.xpath(\"//div[1][contains(@class,'image_container')]/a/img/@src\")\n",
        "starRating = articles.xpath(\"//p[contains(@class,'star-rating')]/@class\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA6BjC2N_cWe"
      },
      "source": [
        "#cleaning and formatting \n",
        "stock = list(map(lambda stock:stock.strip(),availability))\n",
        "images = list(map(lambda img:img.replace('../../../..','http://books.toscrape.com'),imageUrl))\n",
        "rating = list(map(lambda rating:rating.replace('star-rating ',''),starRating))\n",
        "\n",
        "print(title)\n",
        "print(price)\n",
        "print(stock)\n",
        "print(images)\n",
        "print(rating)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6eObzy5_zDI"
      },
      "source": [
        "#Merging all \n",
        "dataSet = zip(title,price,stock,images,rating)\n",
        "print(list(dataSet))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOE7ef8LAWuj"
      },
      "source": [
        "### Example 2: Scraping from multiple pages & loop with Xpath"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PFDfqC8AApp"
      },
      "source": [
        "from lxml.etree import XPath"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "909uSy9oBOH8"
      },
      "source": [
        "baseUrl = \"http://books.toscrape.com/\"\n",
        "#Main URL\n",
        "bookUrl = \"http://books.toscrape.com/catalogue/category/books/food-and-drink_33/index.html\"\n",
        "#Page URL Pattern obtained (eg: page-1.html, page-2.html...)\n",
        "pageUrl = \"http://books.toscrape.com/catalogue/category/books/food-and-drink_33/page-\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyPfVm1ABSJ-"
      },
      "source": [
        "dataSet = []\n",
        "page=1\n",
        "totalPages=1\n",
        "while(page<=totalPages):\n",
        "  print(\"Rows in Dataset: \"+str(len(dataSet)))\n",
        "  if (page==1):\n",
        "      doc = lxml.html.parse(pageUrl+str(page)+\".html\").getroot()\n",
        "      perPageArticles = doc.xpath(\"//*[@id=\\\"default\\\"]//form/strong[3]/text()\")\n",
        "      totalArticles = doc.xpath(\"//*[@id=\\\"default\\\"]//form/strong[1]/text()\")\n",
        "      totalPages = round(int(totalArticles[0])/int(perPageArticles[0]))\n",
        "      print(str(totalArticles[0])+\" Results, showing \"+str(perPageArticles[0])+\" Articles per page\")\n",
        "  else:\n",
        "    doc = lxml.html.parse(pageUrl+str(page)+\".html\").getroot()\n",
        "  #used to find page URL pattern\n",
        "  nextPage = doc.xpath(\"//*[@id=\\\"default\\\"]//ul[contains(@class,'pager')]/li[2]/a/@href\")\n",
        "  if len(nextPage)>0: \n",
        "    print(\"Scraping Page \"+str(page)+\" of \"+str(totalPages)+\". NextPage > \"+str(nextPage[0]))\n",
        "  else:\n",
        "    print(\"Scraping Page \"+str(page)+\" of \"+str(totalPages))\n",
        "\n",
        "  articles = XPath(\"//*[@id='default']//ol/li[position()>0]\")\n",
        "  titlePath = XPath(\".//article[contains(@class,'product_pod')]/h3/a/text()\")\n",
        "  pricePath = XPath(\".//article/div[2]/p[contains(@class,'price_color')]/text()\")\n",
        "  stockPath = XPath(\".//article/div[2]/p[2][contains(@class,'availability')]/text()[normalize-space()]\")\n",
        "  imagePath = XPath(\".//article/div[1][contains(@class,'image_container')]/a/img/@src\")\n",
        "  starRating = XPath(\".//article/p[contains(@class,'star-rating')]/@class\")\n",
        "\n",
        "  #looping through 'articles' found in 'doc' i.e each <li><article> found in Page Source\n",
        "  for row in articles(doc): \n",
        "    title = titlePath(row)[0]\n",
        "    price = pricePath(row)[0]\n",
        "    availability = stockPath(row)[0].strip()\n",
        "    image = imagePath(row)[0]\n",
        "    rating = starRating(row)[0]\n",
        "    #cleaning and formatting applied to image and rating\n",
        "    dataSet.append([title,price,availability,image.replace('../../../..',baseUrl),rating.replace('star-rating','')])\n",
        "  \n",
        "  page+=1 #updating Page Count for While loop\n",
        "\n",
        "#Final Dataset with data from all pages.\n",
        "print(dataSet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1abnsx1sHix2"
      },
      "source": [
        "### Example 3: Using lxml.cssselect to scrape content from a page"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akHFJUELHYMX"
      },
      "source": [
        "from lxml.cssselect import CSSSelector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxU4tSP7H29V"
      },
      "source": [
        "url = 'https://developer.ibm.com/announcements/category/data-science/?fa=date%3ADESC&fb='\n",
        "url_get = requests.get(url)\n",
        "tree = html.document_fromstring(url_get.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc_OYzt2H6Bh"
      },
      "source": [
        "announcements=[]\n",
        "articles = tree.cssselect('.ibm--card > a.ibm--card__block_link')\n",
        "for article in articles:\n",
        " link = article.get('href')\n",
        " atype = article.cssselect('div.ibm--card__body > h5')[0].text.strip()\n",
        " adate = article.cssselect('div.ibm--card__body > h5 > .ibm--card__date')[0].text\n",
        " title = article.cssselect('div.ibm--card__body > h3.ibm--card__title')[0].text_content()\n",
        " excerpt= article.cssselect(' div.ibm--card__body > p.ibm--card__excerpt')[0].text\n",
        " category= article.cssselect('div.ibm--card__bottom > p.cpt-byline__categories span')\n",
        " \n",
        " #only two available on block: except '+'\n",
        " #announcements.append([link,atype,adate,title,excerpt,[category[0].text,category[1].text]])\n",
        " \n",
        " announcements.append([link,atype,adate,title,excerpt,[span.text for span in category if span.text!='+']])\n",
        "print(announcements)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}