{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hwspSec2_BS4_Scrapy.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODnlQ5O9S3g4"
      },
      "source": [
        "!npx degit PacktPublishing/Hands-On-Web-Scraping-with-Python/Chapter05 -f chp5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcMDr8-Uxsz8"
      },
      "source": [
        "import os\n",
        "os.chdir('chp5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_JF2zWl275z"
      },
      "source": [
        "## Exploring BS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCXVozZ1GRSO"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from bs4 import SoupStrainer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTrxAjJE3GKm"
      },
      "source": [
        "html_doc=\"\"\"<html><head><title>The Dormouse's story</title></head>\n",
        "<body>\n",
        "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
        "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
        "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
        "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
        "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
        "and they lived at the bottom of a well.</p>\n",
        "<p class=\"story\">...</p>\n",
        "<h1>Secret agents</h1>\n",
        "<ul>\n",
        " <li data-id=\"10784\">Jason Walters, 003: Found dead in \"A View to a Kill\".</li>\n",
        " <li data-id=\"97865\">Alex Trevelyan, 006: Agent turned terrorist leader; James' nemesis in \"Goldeneye\".</li>\n",
        " <li data-id=\"45732\">James Bond, 007: The main man; shaken but not stirred.</li>\n",
        "</ul>\n",
        "</body>\n",
        "</html>\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0HzpO7f3P2o"
      },
      "source": [
        "tagsA = SoupStrainer(\"a\")\n",
        "soupA = BeautifulSoup(html_doc,'lxml',parse_only=tagsA)\n",
        "print(type(soupA))\n",
        "print(soupA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwcB4MAQ4lnL"
      },
      "source": [
        "print(soupA.prettify())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GZKJ4R-4rKS"
      },
      "source": [
        "print(soupA.a.has_attr('class'))\n",
        "print(soupA.a.has_attr('name'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t4X8Q2z4-JZ"
      },
      "source": [
        "### Searching, Traversing, and iterating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrITDp3R46WR"
      },
      "source": [
        "print(soupA.find(\"a\")) #print(soupA.find(name=\"a\"))\n",
        "\n",
        "print(soupA.find(\"a\",attrs={'class':'sister'}))\n",
        "\n",
        "print(soupA.find(\"a\",attrs={'class':'sister'},text=\"Lacie\"))\n",
        "\n",
        "print(soupA.find(\"a\",attrs={'id':'link3'}))\n",
        "\n",
        "print(soupA.find('a',id=\"link2\"))\n",
        "\n",
        "print(soupA.find_all(\"a\")) \n",
        "\n",
        "#find all <a>, but return only 2 of them\n",
        "print(soupA.find_all(\"a\",limit=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAMwOsp05tdr"
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9gzQ2LG53wx"
      },
      "source": [
        "print(soupA.find(\"a\",text=re.compile(r'cie')))\n",
        "print(soupA.find_all(\"a\",attrs={'id':re.compile(r'3')}))\n",
        "print(soupA.find_all(re.compile(r'a')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0assm9Zq5978"
      },
      "source": [
        "soup=BeautifulSoup(html_doc,'lxml')\n",
        "print(soup.find_all(\"p\",\"story\"))\n",
        "print(soup.find_all(\"p\",\"title\"))\n",
        "print(soup.find_all(\"p\",attrs={'class':['title','story']}))\n",
        "print(soup.find_all([\"p\",\"li\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQCpfha1iEeK"
      },
      "source": [
        "print(soup.find_all(string='Elsie'))\n",
        "print(soup.find_all(text=re.compile(r'El')))\n",
        "print(soup.find_all(\"a\",string=\"Lacie\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXG5jhhTwCLD"
      },
      "source": [
        "for li in soup.li.find_all('li'):\n",
        "  print(li.name, '>', li.get('data-id'),'>',li.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT4fVAbAwTU6"
      },
      "source": [
        "print(soupA.a)\n",
        "print(soup.li)\n",
        "print(soup.p)\n",
        "print(soup.p.b)\n",
        "print(soup.ul.find('li',attrs={'data-id':'45732'}))\n",
        "print(soup.ul.find('li',attrs={'data-id':'45732'}).text)\n",
        "print(soup.p.text)\n",
        "print(soup.p.string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9tvosK3w6hh"
      },
      "source": [
        "### using children & parents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdu3Jh3dw-no"
      },
      "source": [
        "print(list(soup.find('p','story').children))\n",
        "print(list(soup.find('p','story').contents))\n",
        "print(list(soup.find('p','story').descendants))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMi4xvuiOz7M"
      },
      "source": [
        "#using List Comprehension Technique\n",
        "print([a.name for a in soup.find('p','story').children])\n",
        "print([{'tag':a.name,'text':a.text,'class':a.get('class')} for a in soup.find('p','story').children if a.name!=None])\n",
        "print([a.name for a in soup.find('p','story').descendants])\n",
        "print(list(filter(None,[a.name for a in soup.find('p','story').descendants])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGHBWVbFO3XJ"
      },
      "source": [
        "print(soup.find('p','story').findChildren())\n",
        "print(soup.find('p','story').findChild()) #soup.find('p','story').find()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9e-hZ6hPKPU"
      },
      "source": [
        "#print parent element of <a> with class=sister\n",
        "print(soup.find('a','sister').parent)\n",
        "\n",
        "#print parent element name of <a> with class=sister\n",
        "print(soup.find('a','sister').parent.name)\n",
        "\n",
        "#print text from parent element of <a> with class=sister\n",
        "print(soup.find('a','sister').parent.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PhMrADvPLLS"
      },
      "source": [
        "for element in soup.find('a','sister').parents:\n",
        "    print(element.name)\n",
        "\t\n",
        "#find single Parent for selected <a> with class=sister \n",
        "print(soup.find('a','sister').findParent())\n",
        "\n",
        "#find Parents for selected <a> with class=sister \n",
        "print(soup.find('a','sister').findParents())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5zhRgv4PYZE"
      },
      "source": [
        "### using next & previous"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A55KX46ePc2y"
      },
      "source": [
        "print(soup.find('p','story').next)\n",
        "print(soup.find('p','story').next.next)\n",
        "print(soup.find('p','story').next_element)\n",
        "print(soup.find('p','story').next_element.next_element)\n",
        "print(soup.find('p','story').next_element.next_element.next_element)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWtXfhubPwxI"
      },
      "source": [
        "print(soup.find('p','story').previous) #returns empty or new-line. \n",
        "print(soup.find('p','title').next.next.next) #returns empty or newline similar to code above\n",
        "\n",
        "print(soup.find('p','story').previous.previous)\n",
        "print(soup.find('p','story').previous_element) #returns empty or new-line. \n",
        "print(soup.find('p','story').previous_element.previous_element)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCiUIL5GP6Ph"
      },
      "source": [
        "print(soup.find('p','story').previous_element.previous_element.previous_element)\n",
        "print(soup.find('p','title').next.next.previous.previous)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M_eg-YIQSw3"
      },
      "source": [
        "for element in soup.find('ul').next_elements:\n",
        "    print(element)\n",
        "\t\n",
        "print(soup.find('p','story').next)\n",
        "print(soup.find('p','story').next_element)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFwypodOQULH"
      },
      "source": [
        "print(soup.find('p','story').find_next()) #element after next_element\n",
        "print(soup.find('p','story').find_next('h1'))\n",
        "print(soup.find('p','story').find_all_next())\n",
        "print(soup.find('p','story').find_all_next('li',limit=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkiaUjBaQZr8"
      },
      "source": [
        "print(soup.find('ul').previous.previous.previous)\n",
        "print(soup.find('ul').find_previous())\n",
        "print(soup.find('ul').find_previous('p','title'))\n",
        "print(soup.find('ul').find_all_previous('p'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT8eKYjUQdno"
      },
      "source": [
        "print(soup.find('p','title').next_sibling) #returns empty or new-line\n",
        "print(soup.find('p','title').next_sibling.next_sibling) #print(soup.find('p','title').next_sibling.next)\n",
        "print(soup.find('ul').previous_sibling) #returns empty or new-line\n",
        "print(soup.find('ul').previous_sibling.previous_sibling)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0_MsdwKQqS5"
      },
      "source": [
        "#using List Comprehension \n",
        "title = [ele.name for ele in soup.find('p','title').next_siblings]\n",
        "print(list(filter(None,title)))\n",
        "\n",
        "ul = [ele.name for ele in soup.find('ul').previous_siblings]\n",
        "print(list(filter(None,ul)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1CLS6OJQrj0"
      },
      "source": [
        "#find next <p> siblings for selected <p> with class=title\n",
        "print(soup.find('p','title').find_next_siblings('p'))\n",
        "\n",
        "#find single or next sibling for selected <h1>\n",
        "print(soup.find('h1').find_next_sibling())\n",
        "\n",
        "#find single or next sibling <li> for selected <h1>\n",
        "print(soup.find('h1').find_next_sibling('li'))\n",
        "\n",
        "#find first previous sibling to <ul>\n",
        "print(soup.find('ul').find_previous_sibling())\n",
        "\n",
        "#find all previous siblings to <ul>\n",
        "print(soup.find('ul').find_previous_siblings())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDn6Qf-BQvob"
      },
      "source": [
        "### using CSS selector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DN0s8WngQyWX"
      },
      "source": [
        "## EXAMPLE 1 – listing <li> elements with the data-id attribute\n",
        "#using CSS Selectors\n",
        "print(soup.select('li[data-id]'))\n",
        "print(soup.select('ul li[data-id]')[1]) #fetch index 1 only from resulted List\n",
        "print(soup.select_one('li[data-id]'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67itmWrkQ2HL"
      },
      "source": [
        "## EXAMPLE 2 - traversing through elements\n",
        "\n",
        "print(soup.select('p.story > a.sister'))#Selects all <a> with class='sister' that are direct child to <p> with class=\"story\"\n",
        "print(soup.select('p b'))#Selects <b> inside <p>\n",
        "print(soup.select('p + h1'))#Selects immediate <h1> after <p>\n",
        "print(soup.select('p.story + h1'))#Selects immediate <h1> after <p> with class 'story'\n",
        "print(soup.select('p.title + h1'))#Selects immediate <h1> after <p> with class 'title'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBjMs-8vQ8Ck"
      },
      "source": [
        "## EXAMPLE 3 – searching elements based on attribute values\n",
        "\n",
        "print(soup.select('a[href*=\"example.com\"]'))\n",
        "print(soup.select('a[id*=\"link\"]'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2JMwDwlSIyd"
      },
      "source": [
        "### Building web crawler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCDvdTDFTmTj"
      },
      "source": [
        "!python toscrape_quotes.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fx3pwF1MT0nE"
      },
      "source": [
        "## Web Scraping using Scrapy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltR0zM09T4vW"
      },
      "source": [
        "!pip install scrapy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3aVrD8EBTkZ"
      },
      "source": [
        "import scrapy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeK3wIeXDBoX"
      },
      "source": [
        "#create a file named spider_quotes.py \n",
        "#paste the following content\n",
        "# import scrapy\n",
        "\n",
        "# class QuoteSpider(scrapy.Spider):#inheriting from class scrapy from spider\n",
        "#     name='quotes'\n",
        "#     allowed_domains =['quotes.toscrape.com']\n",
        "#     start_urls=['https://quotes.toscrape.com/']\n",
        "#     def parse(self,response):\n",
        "#         title=response.css('title').extract()\n",
        "#         yield {'titletext': title} "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsr2tTGbKWgd"
      },
      "source": [
        "!python spider_quotes.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE_lFjC2j0hy"
      },
      "source": [
        "!scrapy list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUN0O677kfUu"
      },
      "source": [
        "!scrapy crawl quotes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G_yNVlSlVe_"
      },
      "source": [
        "#to export it csv or json file\n",
        "!scrapy crawl quotes -o quotes.csv\n",
        "!scrapy crawl quotes -o quotes.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeAcleFRlwQz"
      },
      "source": [
        "#now deploy the web crawler"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}