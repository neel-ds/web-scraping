{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hwspSec2_Scraping_pyquery.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3l0K_JX2Awam",
        "HygVs3THBCvK",
        "Qs0yxc1oEIo5",
        "zzcrV5eLILAT",
        "094tH8_gKm0i",
        "QKbFBrlMK16U",
        "jKLZoV-bWvez",
        "sy5RKNHpXz4f",
        "DFrDvuxSZDYh",
        "W6omx_cebmjc",
        "qc9y1LJIbrU7"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3l0K_JX2Awam"
      },
      "source": [
        "# Exploring Pyquery"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_NiEdQwDNPv"
      },
      "source": [
        "!npx degit PacktPublishing/Hands-On-Web-Scraping-with-Python/Chapter04 -f chp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhG0Vas9rPys"
      },
      "source": [
        "import os\n",
        "os.chdir('chp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HygVs3THBCvK"
      },
      "source": [
        "## Loading documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epUn7BQvBiJG"
      },
      "source": [
        "pip install pyquery"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QWAfltcAKzF"
      },
      "source": [
        "from pyquery import PyQuery as pq\n",
        "from urllib.request import urlopen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qzyWMxYBbMG"
      },
      "source": [
        "response=urlopen(\"http://www.example.com\").read()\n",
        "docTree=pq(response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTd_5XR-Bw9c"
      },
      "source": [
        "pq(\"https://www.python.org\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRh3DvVgB2JD"
      },
      "source": [
        "site=pq(\"https://www.python.org\")\n",
        "print(type(site))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qax3jw4HB-4w"
      },
      "source": [
        "pq(\"https://www.samsclub.com\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xPX7wTYCFmm"
      },
      "source": [
        " doc = pq('http://www.example.com', parser = 'html') #using parser xml\n",
        " print(type(doc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W68u5MrQDqe_"
      },
      "source": [
        "pgsource=open('test.html','r').read()\n",
        "print(type(pgsource))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMcJvAuIEAkC"
      },
      "source": [
        "page=pq(pgsource)\n",
        "print(type(page))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs0yxc1oEIo5"
      },
      "source": [
        "## Element traversing, attr & pseudo-class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05nD8s2UEGqv"
      },
      "source": [
        "page('title')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-nPDdF0Egh5"
      },
      "source": [
        "page.find('title').text()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-F9-QrdEmPw"
      },
      "source": [
        "page.find('meta[name=\"description\"]').attr('content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RZjOCa0Et_7"
      },
      "source": [
        "page.find('meta[name=\"keywords\"]').attr('content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAQuhJIuE7fJ"
      },
      "source": [
        "btn=page('a.button').html()\n",
        "btn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n9A07p5FF4R"
      },
      "source": [
        "page('ul.menu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EJFqF5aFQwn"
      },
      "source": [
        "page('nav:first')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vibLcJM5FU_y"
      },
      "source": [
        "page('ul:last')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGgZZUh4FZOf"
      },
      "source": [
        "page(':header')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0_bTXlFFdUD"
      },
      "source": [
        "page(':input')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAGACEQAFgbv"
      },
      "source": [
        "page(':empty')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpgWsEFmFjCJ"
      },
      "source": [
        "page(':empty:odd')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny-KEs8qFvOY"
      },
      "source": [
        "page.find('a:last').attr('href')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJnhq3ugGles"
      },
      "source": [
        "page.find('a:eq(0)').text()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yKYYFnDGvNJ"
      },
      "source": [
        "page.find('a:lt(5)').text()\n",
        "#eq : equal\n",
        "#lt : less than\n",
        "#gt: greater than"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40q6vzdaG4WJ"
      },
      "source": [
        "page('p:contains(\"python.org\")').text()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm6T7Pe4HMgY"
      },
      "source": [
        "page('h1.site-headline:first a img')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OprTFlM5H4r6"
      },
      "source": [
        "#.is_ OR .has_class\n",
        "page('h1.site-headline:first a img').is_('.python-logo')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzcrV5eLILAT"
      },
      "source": [
        "## Iterating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAAeaj_DIHeX"
      },
      "source": [
        "meta=page.find('meta[content*=\"Python.org\"]')\n",
        "[item.attr('name') for item in meta.items() if item.attr('name') is not None]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSeer1Y4IcWK"
      },
      "source": [
        "[item.attr('property') for item in meta.items() if item.attr('property') is not None]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR3u0ajoI0bu"
      },
      "source": [
        "social = page.find('a:contains(\"Socialize\") + ul.subnav li a') \n",
        "[item.text() for item in social.items() if item.text() is not None]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsgBf2noI4-1"
      },
      "source": [
        "[item.attr('href') for item in social.items() if item.attr('href') is not None]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDtfGw_dJBFv"
      },
      "source": [
        "webdevs = page.find('div.applications-widget:first ul.menu li:contains(\"Web Development\") a')\n",
        "[item.text() for item in webdevs.items() if item.text() is not None]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g0MT4ohJHSx"
      },
      "source": [
        "eventsList = []\n",
        "upcomingevents = page.find('div.event-widget ul.menu li')\n",
        "for event in upcomingevents.items():\n",
        " time = event.find('time').text()\n",
        " url = event.find('a[href*=\"events/python\"]').attr('href')\n",
        " title = event.find('a[href*=\"events/python\"]').text()\n",
        " eventsList.append([time,title,url])\n",
        "\n",
        "eventsList"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnwigqaYJymu"
      },
      "source": [
        "buttons = page.find('a.button')\n",
        "for item in buttons.items():\n",
        "  print(item.text(),' :: ',item.attr('href'))\n",
        "\n",
        "#buttons = page.find('a.button:even/odd') print even/odd result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "094tH8_gKm0i"
      },
      "source": [
        "# Web Scraping using pyquery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKbFBrlMK16U"
      },
      "source": [
        "## Example 1: Scraping DS announcements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWoXUMGXKMpn"
      },
      "source": [
        "from pyquery import PyQuery as pq\n",
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d5J1y-iTH2l"
      },
      "source": [
        "dataSet=list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApiU8H70TXYY"
      },
      "source": [
        "sourceUrl='https://developer.ibm.com/announcements/'\n",
        "def read_url(url):\n",
        "  \"\"\"Read given Url , Returns pyquery object for page content\"\"\"\n",
        "  pageSource = requests.get(url).content\n",
        "  return pq(pageSource) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne1UZlNZUQeu"
      },
      "source": [
        "def get_details(page):\n",
        "    \"\"\"read 'page' url and append list of queried items to dataSet\"\"\"\n",
        "    response = read_url(page)\n",
        "\n",
        "    articles = response.find('.ibm--card > a.ibm--card__block_link')\n",
        "    print(\"\\nTotal articles found :\", articles.__len__(), ' in Page: ', page)\n",
        "    for article in articles.items():\n",
        "        link = article.attr('href')\n",
        "        articlebody = article.find('div.ibm--card__body')\n",
        "        adate = articlebody.find('h5 > .ibm--card__date').text()\n",
        "        articlebody.find('h5 > .ibm--card__date').remove()\n",
        "        atype = articlebody.find('h5').text().strip()\n",
        "        title = articlebody.find('h3.ibm--card__title').text().encode('utf-8')\n",
        "        excerpt = articlebody.find('p.ibm--card__excerpt').text().encode('utf-8')\n",
        "        category = article.find('div.ibm--card__bottom > p.cpt-byline__categories span')\n",
        "        if link:\n",
        "            link = str(link).replace('/announcements/', sourceUrl)\n",
        "            categories = [span.text for span in category if span.text != '+']\n",
        "            dataSet.append([link, atype, adate, title, excerpt,\",\".join(categories)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTX2YnkWTcSK"
      },
      "source": [
        "mainUrl = sourceUrl+\"category/data-science/?fa=date:DESC&fb=\"\n",
        "pageUrls = [sourceUrl+\"category/data-science/page/%(page)s?fa=date:DESC&fb=\" % {'page': page} for page in range(1, 3)]\n",
        "for pages in pageUrls:\n",
        " get_details(pages)\n",
        "print(\"\\nTotal articles collected: \", len(dataSet))\n",
        "print(dataSet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWCp5PlDT1kw"
      },
      "source": [
        "# just to verify as it's giving different output mentioned in book\n",
        "!python \"example1_ibm_announcements.py\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKLZoV-bWvez"
      },
      "source": [
        "## Example 2: Scraping infor from nested links"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiOVwrFJXfCB"
      },
      "source": [
        "sourceUrl = 'http://quotes.toscrape.com/tag/books/'\n",
        "dataSet = list()\n",
        "keys = ['quote_tags','author_url','author_name','born_date','born_location','quote_title']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_vvy0uwXmBs"
      },
      "source": [
        "def read_url(url):\n",
        "    \"\"\"Read given Url , Returns pyquery object for page content\"\"\"\n",
        "    pageSource = pq(url)\n",
        "    return pq(pageSource)\n",
        "\n",
        "\n",
        "def get_details(page):\n",
        "    \"\"\"read 'page' url and append list of queried items to dataSet\"\"\"\n",
        "    nextPage = True\n",
        "    pageNo = 1\n",
        "    while (nextPage):\n",
        "        response = read_url(page + 'page/' + str(pageNo))\n",
        "        if response.find(\"ul.pager:has('li.next')\"):\n",
        "            nextPage = True\n",
        "        else:\n",
        "            nextPage = False\n",
        "\n",
        "        quotes = response.find('.quote')\n",
        "        print(\"\\nTotal Quotes found :\", quotes.__len__(), ' in Page: ', pageNo)\n",
        "        for quote in quotes.items():\n",
        "            title = quote.find('[itemprop=\"text\"]:first').text()\n",
        "            author = quote.find('[itemprop=\"author\"]:first').text()\n",
        "            authorLink = quote.find('a[href*=\"/author/\"]:first').attr('href')\n",
        "            tags = quote.find('.tags [itemprop=\"keywords\"]').attr('content')\n",
        "\n",
        "            if authorLink:\n",
        "                authorLink = 'http://quotes.toscrape.com' + authorLink\n",
        "                linkDetail = read_url(authorLink)\n",
        "                born_date = linkDetail.find('.author-born-date').text()\n",
        "                born_location = linkDetail.find('.author-born-location').text()\n",
        "                if born_location.startswith('in'):\n",
        "                    born_location = born_location.replace('in ','')\n",
        "                dataSet.append(dict(zip(keys,[tags,authorLink,author,born_date,born_location,title[0:50]])))\n",
        "        pageNo += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt4WMwN3XluH"
      },
      "source": [
        "get_details(sourceUrl)\n",
        "print(\"\\nTotal Quotes collected: \", len(dataSet))\n",
        "print(dataSet)\n",
        "for info in dataSet:\n",
        "   print(info['author_name'],' born on ',info['born_date'], ' in ',info['born_location'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJf0pVUnWBcf"
      },
      "source": [
        "!python \"example2_quotes_authors.py\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy5RKNHpXz4f"
      },
      "source": [
        "## Example 3: AHL playoff results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMOLxckAYqb1"
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z67-WgdWXXbn"
      },
      "source": [
        "sourceUrl = 'http://www.flyershistory.com/cgi-bin/ml-poffs.cgi'\n",
        "dataSet = list()\n",
        "keys = ['year','month','day','game_date','team1', 'team1_score', 'team2', 'team2_score', 'game_status']\n",
        "\n",
        "def read_url(url):\n",
        "    \"\"\"Read given Url , Returns pyquery object for page content\"\"\"\n",
        "    pageSource = pq(url)\n",
        "    return pq(pageSource)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egAGJUM5YS7u"
      },
      "source": [
        "page = read_url(sourceUrl)\n",
        "\n",
        "tableRows = page.find(\"h1:contains('AHL Playoff Results') + table tr\")\n",
        "print(\"\\nTotal rows found :\", tableRows.__len__())\n",
        "\n",
        "for tr in tableRows.items():\n",
        "    team1 = tr.find('td').eq(1).text()\n",
        "    if team1 != '':\n",
        "            game_date = tr.find('td').eq(0).text()\n",
        "            dates = re.search(r'(.*)-(.*)-(.*)',game_date)\n",
        "\n",
        "            team1_score = tr.find('td').eq(2).text()\n",
        "            team2 = tr.find('td').eq(4).text()\n",
        "            team2_score = tr.find('td').eq(5).text()\n",
        "\n",
        "            #check Game Status should be either 'W' or 'L'\n",
        "            game_status = tr.find('td').eq(6).text()\n",
        "            if not re.match(r'[WL]',game_status):\n",
        "                game_status = tr.find('td').eq(7).text()\n",
        "\n",
        "            #breaking down date in year,month and day\n",
        "            year = dates.group(3)\n",
        "            month = dates.group(2)\n",
        "            day = dates.group(1)\n",
        "            if len(year)==2 and int(year)>=68:\n",
        "                year = '19'+year\n",
        "            elif len(year)==2 and int(year) <68:\n",
        "                year = '20'+year\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "            #appending individual data list to the dataSet\n",
        "            dataSet.append([year,month,day,game_date,team1,team1_score,team2,team2_score,game_status])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdZoo7F8YiVS"
      },
      "source": [
        "print(\"\\nTotal Game Status, found :\", len(dataSet))\n",
        "print(dataSet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bHIItGvYx1o"
      },
      "source": [
        "!python \"example3_AHL.py\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFrDvuxSZDYh"
      },
      "source": [
        "## Example 4: Collecting URLs from sitemap.xml"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRd2X3GvY4qg"
      },
      "source": [
        "sitemap=requests.get(\"https://webscraping.com/sitemap.xml\").content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sPQoxFfZ5xs"
      },
      "source": [
        "sitemap.decode()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6omx_cebmjc"
      },
      "source": [
        "### Case 1: Using html parser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9yzd2BcaBLW"
      },
      "source": [
        "urlHTML=pq(sitemap,parser='html')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2Y5mk85bPy7"
      },
      "source": [
        "print(\"Children Length: \",urlHTML.children().__len__())\n",
        "print(\"First Children: \",urlHTML.children().eq(0))\n",
        "print(\"Inner Child/First Children: \",urlHTML.children().children().eq(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJv0YZX3bSSE"
      },
      "source": [
        "dataSet=list()\n",
        "for url in urlHTML.children().find('loc:contains(\"blog\")').items():\n",
        " dataSet.append(url.text())\n",
        "print(\"Length of dataSet: \", len(dataSet))\n",
        "print(dataSet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc9y1LJIbrU7"
      },
      "source": [
        "### Case 2: Using XML parser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "he0Y_Ilqbi7x"
      },
      "source": [
        "urlXML=pq(sitemap,parser='xml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT8Eki8kby-V"
      },
      "source": [
        "print(\"Children Length: \",urlXML.children().__len__())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGDQEgSsb2zP"
      },
      "source": [
        "print(\"First Children: \", urlXML.children().eq(0))\n",
        "print(\"Inner Child/First Children: \", urlXML.children().children().eq(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiCGOIDGb50Y"
      },
      "source": [
        "dataSet=list()\n",
        "for url in urlXML.children().find('loc:contains(\"blog\")').items():\n",
        " dataSet.append(url.text())\n",
        "print(\"Length of dataSet: \", len(dataSet))\n",
        "print(dataSet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW-eL01ib9Wj"
      },
      "source": [
        "for url in urlXML.children().children().items():\n",
        " print(url)\n",
        " break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaYYomYAcCVj"
      },
      "source": [
        "for url in urlXML.remove_namespaces().children().find('loc:contains(\"blog\")').items():\n",
        " dataSet.append(url.text())\n",
        "print(\"Length of dataSet: \", len(dataSet))\n",
        "print(dataSet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dxPg6_fcLTp"
      },
      "source": [
        "print(\"URLs using Children: \",urlXML.children().text()) \n",
        "#print(\"URLs using Children: \",urlXML.children().children().text()) \n",
        "#print(\"URLs using Children: \",urlXML.text())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mdwNupmcMOY"
      },
      "source": [
        "blogXML = re.split(r'\\s',urlXML .children().text())\n",
        "print(\"Length of blogXML: \",len(blogXML))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGxiV2-icbsH"
      },
      "source": [
        "dataSet= list(filter(lambda blogXML:re.findall(r'blog',blogXML),blogXML))\n",
        "print(\"Length of dataSet: \",len(dataSet))\n",
        "print(\"Blog Urls: \",dataSet)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}